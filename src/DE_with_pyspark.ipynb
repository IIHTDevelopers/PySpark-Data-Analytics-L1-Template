{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644bb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate spark session\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"appName\").config(\"spark.driver.extraClassPath\", \"C:\\\\mysql-connector-j-8.0.33.jar\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d7bdc79",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e53b9aa2",
   "metadata": {},
   "source": [
    "## Q1) 1.1 Load data from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a9b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_mysql(spark :pyspark.sql.SparkSession, db_name :str, table_name :str) \\\n",
    "                        -> pyspark.sql.DataFrame:\n",
    "    '''\n",
    "        â€“ load data from MySQL table 'table_name' from database 'db_name' and return the \n",
    "        table as a spark dataframe.\n",
    "\n",
    "        For the mysql connection use below information:\n",
    "            jdbc driver: 'com.mysql.cj.jdbc.Driver'\n",
    "            Hostname: 'localhost'\n",
    "            Port: 3306\n",
    "            Database: 'classicmodels'\n",
    "            Table_name: 'order_details'\n",
    "            Username: 'root'\n",
    "            Password: 'pass@word1'\n",
    "    '''\n",
    "    # your code goes here\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a88f4a",
   "metadata": {},
   "source": [
    "## Q2) 1.2 Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d548d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(spark, csv_file_name):\n",
    "        '''\n",
    "        Load data from CSV file 'csv_file_name' and return a spark Dataframe\n",
    "        '''\n",
    "        # your code goes here\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c810a4aa",
   "metadata": {},
   "source": [
    "## Q3) 1.3  Load data from flat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_flatfile(spark :pyspark.sql.SparkSession, txt_file_name: str) \\\n",
    "                      -> pyspark.sql.DataFrame:\n",
    "    '''\n",
    "    Load data from flat file 'txt_file_name' separated with ':' and return a spark Dataframe\n",
    "    PS: The data files for this assignment are in 'data' folder\n",
    "    You can access full path of 'data/' folder using 'DATA_FOLDER' variable\n",
    "    from constants.py\n",
    "    '''\n",
    "    # your code goes here\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b29688d",
   "metadata": {},
   "source": [
    "# 2. Transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72a25702",
   "metadata": {},
   "source": [
    "## Q4) 2.1  Clean product's MSRP data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524eb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_product_MSRP_column(spark :pyspark.sql.SparkSession) -> pyspark.sql.DataFrame:\n",
    "    '''\n",
    "    Due to a data entry issues MSRP, the selling price is lower than its buyPrice for some\n",
    "    products. Change MSRP to 1.4 times of the buyPrice for such products and cast it to two\n",
    "    decimal places.\n",
    "    \n",
    "    Return a spark dataframe with following columns.\n",
    "    |productCode|productName|productLine|productScale|productVendor|productDescription|quantityInStock|buyPrice|MSRP|\n",
    "    '''\n",
    "    # your code goes here\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dae8471",
   "metadata": {},
   "source": [
    "## Q5) 2.3  Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info(spark :pyspark.sql.SparkSession) -> pyspark.sql.DataFrame:\n",
    "    '''\n",
    "    Return a consolidated customer info using structs.\n",
    "    \n",
    "    Return a spark dataframe with following columns.\n",
    "    |custID|custName|country|#orders|totalMoneySpent|creditLimit|\n",
    "    '''\n",
    "    customer_schema = StructType([ \\\n",
    "      StructField(\"custID\",StringType(),True), \\\n",
    "      StructField(\"custName\",StringType(),True), \\\n",
    "      StructField(\"country\",StringType(),True), \\\n",
    "      StructField(\"#orders\",IntegerType(),True), \\\n",
    "      StructField(\"totalMoneySpent\", DoubleType(), True), \\\n",
    "      StructField(\"creditLimit\", IntegerType(), True), \\\n",
    "    ])\n",
    "    # your code goes here\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d807e972",
   "metadata": {},
   "source": [
    "## Q6) Analytics 3.4 Return Top 5 big spenders(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457667a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_5_big_spend_countries(spark :pyspark.sql.SparkSession) -> pyspark.sql.DataFrame:\n",
    "    '''\n",
    "    Return top 5 big countries which had spent the most $(highest order value).\n",
    "    \n",
    "    Return a spark dataframe with following columns.\n",
    "    |country|totalOrderValue|\n",
    "    '''\n",
    "    # your code goes here\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
